2025-02-11 14:44:57.411082: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-11 14:44:57.419438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1739285097.428378  101527 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1739285097.431140  101527 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-11 14:44:59.259120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I0000 00:00:1739285102.333338  101527 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22497 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6
2025-02-11 14:45:03.735043: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1739285103.745558  101575 service.cc:148] XLA service 0x7f31ec019f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1739285103.745577  101575 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6
2025-02-11 14:45:03.769993: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
I0000 00:00:1739285103.899141  101575 cuda_dnn.cc:529] Loaded cuDNN version 90501
2025-02-11 14:45:04.563311: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2407', 88 bytes spill stores, 88 bytes spill loads

2025-02-11 14:45:04.750485: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2407_0', 692 bytes spill stores, 636 bytes spill loads

2025-02-11 14:45:04.769295: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2407', 312 bytes spill stores, 312 bytes spill loads

2025-02-11 14:45:05.030052: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2407_0', 52 bytes spill stores, 52 bytes spill loads

2025-02-11 14:45:05.252855: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2407', 80 bytes spill stores, 80 bytes spill loads

2025-02-11 14:45:05.321332: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2407', 1140 bytes spill stores, 1112 bytes spill loads

2025-02-11 14:45:05.521499: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2667', 1204 bytes spill stores, 932 bytes spill loads

I0000 00:00:1739285108.224797  101575 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
slurmstepd: error: *** JOB 1066031 ON falcon-01 CANCELLED AT 2025-02-11T14:45:10 ***
